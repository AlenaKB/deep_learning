{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initial imports\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path(\"./winequality.csv\")\n",
    "df = pd.read_csv(data, delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:11].values\n",
    "\n",
    "y = df['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_hidden_nodes = 8\n",
    "number_input_features = 11\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units=number_hidden_nodes, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "nn.add(Dense(units=1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1119 samples, validate on 480 samples\n",
      "Epoch 1/200\n",
      "1119/1119 [==============================] - 1s 765us/sample - loss: 785.6204 - mse: 785.6205 - val_loss: 419.4647 - val_mse: 419.4648\n",
      "Epoch 2/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 324.1499 - mse: 324.1498 - val_loss: 144.1616 - val_mse: 144.1616\n",
      "Epoch 3/200\n",
      "1119/1119 [==============================] - 0s 99us/sample - loss: 112.0051 - mse: 112.0051 - val_loss: 43.0232 - val_mse: 43.0232\n",
      "Epoch 4/200\n",
      "1119/1119 [==============================] - 0s 94us/sample - loss: 35.8790 - mse: 35.8790 - val_loss: 16.3890 - val_mse: 16.3890\n",
      "Epoch 5/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 15.6694 - mse: 15.6694 - val_loss: 11.4763 - val_mse: 11.4763\n",
      "Epoch 6/200\n",
      "1119/1119 [==============================] - 0s 97us/sample - loss: 10.0284 - mse: 10.0284 - val_loss: 9.7730 - val_mse: 9.7730\n",
      "Epoch 7/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 7.8231 - mse: 7.8231 - val_loss: 8.5843 - val_mse: 8.5843\n",
      "Epoch 8/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 6.7509 - mse: 6.7509 - val_loss: 7.6571 - val_mse: 7.6571\n",
      "Epoch 9/200\n",
      "1119/1119 [==============================] - 0s 96us/sample - loss: 6.1752 - mse: 6.1752 - val_loss: 6.9372 - val_mse: 6.9372\n",
      "Epoch 10/200\n",
      "1119/1119 [==============================] - 0s 98us/sample - loss: 5.6914 - mse: 5.6914 - val_loss: 6.3642 - val_mse: 6.3642\n",
      "Epoch 11/200\n",
      "1119/1119 [==============================] - 0s 94us/sample - loss: 5.2733 - mse: 5.2733 - val_loss: 5.8619 - val_mse: 5.8619\n",
      "Epoch 12/200\n",
      "1119/1119 [==============================] - 0s 100us/sample - loss: 4.8668 - mse: 4.8668 - val_loss: 5.4243 - val_mse: 5.4243\n",
      "Epoch 13/200\n",
      "1119/1119 [==============================] - 0s 92us/sample - loss: 4.5122 - mse: 4.5122 - val_loss: 5.0446 - val_mse: 5.0446\n",
      "Epoch 14/200\n",
      "1119/1119 [==============================] - 0s 96us/sample - loss: 4.1852 - mse: 4.1852 - val_loss: 4.6568 - val_mse: 4.6568\n",
      "Epoch 15/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 3.8882 - mse: 3.8882 - val_loss: 4.3381 - val_mse: 4.3381\n",
      "Epoch 16/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 3.6181 - mse: 3.6181 - val_loss: 4.0843 - val_mse: 4.0843\n",
      "Epoch 17/200\n",
      "1119/1119 [==============================] - 0s 92us/sample - loss: 3.3784 - mse: 3.3784 - val_loss: 3.7947 - val_mse: 3.7947\n",
      "Epoch 18/200\n",
      "1119/1119 [==============================] - 0s 97us/sample - loss: 3.1679 - mse: 3.1679 - val_loss: 3.5560 - val_mse: 3.5560\n",
      "Epoch 19/200\n",
      "1119/1119 [==============================] - 0s 101us/sample - loss: 2.9738 - mse: 2.9738 - val_loss: 3.3607 - val_mse: 3.3607\n",
      "Epoch 20/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 2.7963 - mse: 2.7963 - val_loss: 3.1795 - val_mse: 3.1795\n",
      "Epoch 21/200\n",
      "1119/1119 [==============================] - 0s 92us/sample - loss: 2.6459 - mse: 2.6459 - val_loss: 3.0111 - val_mse: 3.0111\n",
      "Epoch 22/200\n",
      "1119/1119 [==============================] - 0s 108us/sample - loss: 2.5032 - mse: 2.5032 - val_loss: 2.8744 - val_mse: 2.8744\n",
      "Epoch 23/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 2.3827 - mse: 2.3827 - val_loss: 2.7435 - val_mse: 2.7435\n",
      "Epoch 24/200\n",
      "1119/1119 [==============================] - 0s 106us/sample - loss: 2.2665 - mse: 2.2665 - val_loss: 2.6133 - val_mse: 2.6133\n",
      "Epoch 25/200\n",
      "1119/1119 [==============================] - 0s 110us/sample - loss: 2.1717 - mse: 2.1717 - val_loss: 2.5066 - val_mse: 2.5066\n",
      "Epoch 26/200\n",
      "1119/1119 [==============================] - 0s 112us/sample - loss: 2.0800 - mse: 2.0800 - val_loss: 2.4104 - val_mse: 2.4104\n",
      "Epoch 27/200\n",
      "1119/1119 [==============================] - 0s 115us/sample - loss: 1.9955 - mse: 1.9955 - val_loss: 2.3310 - val_mse: 2.3310\n",
      "Epoch 28/200\n",
      "1119/1119 [==============================] - 0s 94us/sample - loss: 1.9200 - mse: 1.9200 - val_loss: 2.2574 - val_mse: 2.2574\n",
      "Epoch 29/200\n",
      "1119/1119 [==============================] - 0s 96us/sample - loss: 1.8575 - mse: 1.8575 - val_loss: 2.1966 - val_mse: 2.1966\n",
      "Epoch 30/200\n",
      "1119/1119 [==============================] - 0s 108us/sample - loss: 1.7970 - mse: 1.7970 - val_loss: 2.1329 - val_mse: 2.1329\n",
      "Epoch 31/200\n",
      "1119/1119 [==============================] - 0s 107us/sample - loss: 1.7444 - mse: 1.7444 - val_loss: 2.0678 - val_mse: 2.0678\n",
      "Epoch 32/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 1.6909 - mse: 1.6909 - val_loss: 2.0329 - val_mse: 2.0329\n",
      "Epoch 33/200\n",
      "1119/1119 [==============================] - 0s 109us/sample - loss: 1.6510 - mse: 1.6510 - val_loss: 1.9907 - val_mse: 1.9907\n",
      "Epoch 34/200\n",
      "1119/1119 [==============================] - 0s 105us/sample - loss: 1.6111 - mse: 1.6111 - val_loss: 1.9239 - val_mse: 1.9239\n",
      "Epoch 35/200\n",
      "1119/1119 [==============================] - 0s 106us/sample - loss: 1.5772 - mse: 1.5772 - val_loss: 1.8972 - val_mse: 1.8972\n",
      "Epoch 36/200\n",
      "1119/1119 [==============================] - 0s 111us/sample - loss: 1.5334 - mse: 1.5334 - val_loss: 1.8552 - val_mse: 1.8552\n",
      "Epoch 37/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 1.4995 - mse: 1.4995 - val_loss: 1.8199 - val_mse: 1.8199\n",
      "Epoch 38/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 1.4696 - mse: 1.4696 - val_loss: 1.8003 - val_mse: 1.8003\n",
      "Epoch 39/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 1.4461 - mse: 1.4461 - val_loss: 1.7930 - val_mse: 1.7930\n",
      "Epoch 40/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 1.4160 - mse: 1.4160 - val_loss: 1.7336 - val_mse: 1.7336\n",
      "Epoch 41/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 1.3880 - mse: 1.3880 - val_loss: 1.6954 - val_mse: 1.6954\n",
      "Epoch 42/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 1.3644 - mse: 1.3644 - val_loss: 1.6845 - val_mse: 1.6845\n",
      "Epoch 43/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 1.3417 - mse: 1.3417 - val_loss: 1.6473 - val_mse: 1.6473\n",
      "Epoch 44/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 1.3180 - mse: 1.3180 - val_loss: 1.6298 - val_mse: 1.6298\n",
      "Epoch 45/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 1.2954 - mse: 1.2954 - val_loss: 1.6065 - val_mse: 1.6065\n",
      "Epoch 46/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 1.2778 - mse: 1.2778 - val_loss: 1.5983 - val_mse: 1.5983\n",
      "Epoch 47/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 1.2524 - mse: 1.2524 - val_loss: 1.5152 - val_mse: 1.5152\n",
      "Epoch 48/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 1.2318 - mse: 1.2318 - val_loss: 1.5206 - val_mse: 1.5206\n",
      "Epoch 49/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 1.2121 - mse: 1.2121 - val_loss: 1.4612 - val_mse: 1.4612\n",
      "Epoch 50/200\n",
      "1119/1119 [==============================] - 0s 97us/sample - loss: 1.1932 - mse: 1.1932 - val_loss: 1.4601 - val_mse: 1.4601\n",
      "Epoch 51/200\n",
      "1119/1119 [==============================] - 0s 98us/sample - loss: 1.1724 - mse: 1.1724 - val_loss: 1.4327 - val_mse: 1.4327\n",
      "Epoch 52/200\n",
      "1119/1119 [==============================] - 0s 96us/sample - loss: 1.1549 - mse: 1.1549 - val_loss: 1.4240 - val_mse: 1.4240\n",
      "Epoch 53/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 1.1336 - mse: 1.1336 - val_loss: 1.3804 - val_mse: 1.3804\n",
      "Epoch 54/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 1.1193 - mse: 1.1193 - val_loss: 1.3810 - val_mse: 1.3810\n",
      "Epoch 55/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 1.1002 - mse: 1.1002 - val_loss: 1.3385 - val_mse: 1.3385\n",
      "Epoch 56/200\n",
      "1119/1119 [==============================] - 0s 92us/sample - loss: 1.0814 - mse: 1.0814 - val_loss: 1.3171 - val_mse: 1.3171\n",
      "Epoch 57/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 1.0639 - mse: 1.0639 - val_loss: 1.2836 - val_mse: 1.2836\n",
      "Epoch 58/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 1.0472 - mse: 1.0472 - val_loss: 1.2847 - val_mse: 1.2847\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1119 [==============================] - 0s 86us/sample - loss: 1.0361 - mse: 1.0361 - val_loss: 1.2572 - val_mse: 1.2572\n",
      "Epoch 60/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 1.0147 - mse: 1.0147 - val_loss: 1.2288 - val_mse: 1.2288\n",
      "Epoch 61/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 1.0054 - mse: 1.0054 - val_loss: 1.1831 - val_mse: 1.1831\n",
      "Epoch 62/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.9871 - mse: 0.9871 - val_loss: 1.2089 - val_mse: 1.2089\n",
      "Epoch 63/200\n",
      "1119/1119 [==============================] - 0s 91us/sample - loss: 0.9698 - mse: 0.9698 - val_loss: 1.1603 - val_mse: 1.1603\n",
      "Epoch 64/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.9546 - mse: 0.9546 - val_loss: 1.1305 - val_mse: 1.1305\n",
      "Epoch 65/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.9420 - mse: 0.9420 - val_loss: 1.0942 - val_mse: 1.0942\n",
      "Epoch 66/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 0.9276 - mse: 0.9276 - val_loss: 1.1083 - val_mse: 1.1083\n",
      "Epoch 67/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.9142 - mse: 0.9142 - val_loss: 1.0575 - val_mse: 1.0575\n",
      "Epoch 68/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.9024 - mse: 0.9024 - val_loss: 1.0737 - val_mse: 1.0737\n",
      "Epoch 69/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.8914 - mse: 0.8914 - val_loss: 1.0251 - val_mse: 1.0251\n",
      "Epoch 70/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.8760 - mse: 0.8760 - val_loss: 1.0288 - val_mse: 1.0288\n",
      "Epoch 71/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.8666 - mse: 0.8666 - val_loss: 1.0076 - val_mse: 1.0076\n",
      "Epoch 72/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.8600 - mse: 0.8600 - val_loss: 0.9964 - val_mse: 0.9964\n",
      "Epoch 73/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.8404 - mse: 0.8404 - val_loss: 0.9904 - val_mse: 0.9904\n",
      "Epoch 74/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.8296 - mse: 0.8296 - val_loss: 0.9595 - val_mse: 0.9595\n",
      "Epoch 75/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.8219 - mse: 0.8219 - val_loss: 0.9752 - val_mse: 0.9752\n",
      "Epoch 76/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.8127 - mse: 0.8127 - val_loss: 0.9458 - val_mse: 0.9458\n",
      "Epoch 77/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.8002 - mse: 0.8002 - val_loss: 0.9314 - val_mse: 0.9314\n",
      "Epoch 78/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.7902 - mse: 0.7902 - val_loss: 0.9351 - val_mse: 0.9351\n",
      "Epoch 79/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.7815 - mse: 0.7815 - val_loss: 0.9098 - val_mse: 0.9098\n",
      "Epoch 80/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.7691 - mse: 0.7691 - val_loss: 0.9051 - val_mse: 0.9051\n",
      "Epoch 81/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.7650 - mse: 0.7650 - val_loss: 0.8632 - val_mse: 0.8632\n",
      "Epoch 82/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.7510 - mse: 0.7510 - val_loss: 0.8951 - val_mse: 0.8951\n",
      "Epoch 83/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.7468 - mse: 0.7468 - val_loss: 0.8367 - val_mse: 0.8367\n",
      "Epoch 84/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.7347 - mse: 0.7347 - val_loss: 0.8590 - val_mse: 0.8590\n",
      "Epoch 85/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.7286 - mse: 0.7286 - val_loss: 0.8199 - val_mse: 0.8199\n",
      "Epoch 86/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.7178 - mse: 0.7178 - val_loss: 0.8209 - val_mse: 0.8209\n",
      "Epoch 87/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.7104 - mse: 0.7104 - val_loss: 0.8220 - val_mse: 0.8220\n",
      "Epoch 88/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.6996 - mse: 0.6996 - val_loss: 0.7717 - val_mse: 0.7717\n",
      "Epoch 89/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.6986 - mse: 0.6986 - val_loss: 0.7976 - val_mse: 0.7976\n",
      "Epoch 90/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.6881 - mse: 0.6881 - val_loss: 0.7837 - val_mse: 0.7837\n",
      "Epoch 91/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.6833 - mse: 0.6833 - val_loss: 0.7543 - val_mse: 0.7543\n",
      "Epoch 92/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.6762 - mse: 0.6762 - val_loss: 0.7365 - val_mse: 0.7365\n",
      "Epoch 93/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.6668 - mse: 0.6668 - val_loss: 0.7518 - val_mse: 0.7518\n",
      "Epoch 94/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.6612 - mse: 0.6612 - val_loss: 0.7332 - val_mse: 0.7332\n",
      "Epoch 95/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.6507 - mse: 0.6507 - val_loss: 0.7538 - val_mse: 0.7538\n",
      "Epoch 96/200\n",
      "1119/1119 [==============================] - 0s 95us/sample - loss: 0.6484 - mse: 0.6484 - val_loss: 0.7204 - val_mse: 0.7204\n",
      "Epoch 97/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.6365 - mse: 0.6365 - val_loss: 0.7402 - val_mse: 0.7402\n",
      "Epoch 98/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.6321 - mse: 0.6321 - val_loss: 0.6896 - val_mse: 0.6896\n",
      "Epoch 99/200\n",
      "1119/1119 [==============================] - 0s 91us/sample - loss: 0.6312 - mse: 0.6312 - val_loss: 0.6953 - val_mse: 0.6953\n",
      "Epoch 100/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.6225 - mse: 0.6225 - val_loss: 0.7214 - val_mse: 0.7214\n",
      "Epoch 101/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.6199 - mse: 0.6199 - val_loss: 0.6922 - val_mse: 0.6922\n",
      "Epoch 102/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 0.6098 - mse: 0.6098 - val_loss: 0.6893 - val_mse: 0.6893\n",
      "Epoch 103/200\n",
      "1119/1119 [==============================] - 0s 91us/sample - loss: 0.6014 - mse: 0.6014 - val_loss: 0.6626 - val_mse: 0.6626\n",
      "Epoch 104/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.6052 - mse: 0.6052 - val_loss: 0.6933 - val_mse: 0.6933\n",
      "Epoch 105/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.5967 - mse: 0.5967 - val_loss: 0.6677 - val_mse: 0.6677\n",
      "Epoch 106/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.5909 - mse: 0.5909 - val_loss: 0.6687 - val_mse: 0.6687\n",
      "Epoch 107/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.5922 - mse: 0.5922 - val_loss: 0.6721 - val_mse: 0.6721\n",
      "Epoch 108/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.5846 - mse: 0.5846 - val_loss: 0.6301 - val_mse: 0.6301\n",
      "Epoch 109/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.5731 - mse: 0.5731 - val_loss: 0.6346 - val_mse: 0.6346\n",
      "Epoch 110/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.5735 - mse: 0.5735 - val_loss: 0.6160 - val_mse: 0.6160\n",
      "Epoch 111/200\n",
      "1119/1119 [==============================] - 0s 98us/sample - loss: 0.5738 - mse: 0.5738 - val_loss: 0.6594 - val_mse: 0.6594\n",
      "Epoch 112/200\n",
      "1119/1119 [==============================] - 0s 91us/sample - loss: 0.5622 - mse: 0.5622 - val_loss: 0.6195 - val_mse: 0.6195\n",
      "Epoch 113/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 0.5583 - mse: 0.5583 - val_loss: 0.6065 - val_mse: 0.6065\n",
      "Epoch 114/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.5558 - mse: 0.5558 - val_loss: 0.6040 - val_mse: 0.6040\n",
      "Epoch 115/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.5504 - mse: 0.5504 - val_loss: 0.5958 - val_mse: 0.5958\n",
      "Epoch 116/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.5468 - mse: 0.5468 - val_loss: 0.6007 - val_mse: 0.6007\n",
      "Epoch 117/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.5415 - mse: 0.5415 - val_loss: 0.6033 - val_mse: 0.6033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.5369 - mse: 0.5369 - val_loss: 0.5958 - val_mse: 0.5958\n",
      "Epoch 119/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.5352 - mse: 0.5352 - val_loss: 0.5743 - val_mse: 0.5743\n",
      "Epoch 120/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.5346 - mse: 0.5346 - val_loss: 0.5787 - val_mse: 0.5787\n",
      "Epoch 121/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.5304 - mse: 0.5304 - val_loss: 0.5852 - val_mse: 0.5852\n",
      "Epoch 122/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.5266 - mse: 0.5266 - val_loss: 0.5632 - val_mse: 0.5632\n",
      "Epoch 123/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.5230 - mse: 0.5230 - val_loss: 0.5780 - val_mse: 0.5780\n",
      "Epoch 124/200\n",
      "1119/1119 [==============================] - 0s 94us/sample - loss: 0.5210 - mse: 0.5210 - val_loss: 0.5712 - val_mse: 0.5712\n",
      "Epoch 125/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.5160 - mse: 0.5160 - val_loss: 0.5502 - val_mse: 0.5502\n",
      "Epoch 126/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.5158 - mse: 0.5158 - val_loss: 0.5547 - val_mse: 0.5547\n",
      "Epoch 127/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.5133 - mse: 0.5133 - val_loss: 0.5528 - val_mse: 0.5528\n",
      "Epoch 128/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.5063 - mse: 0.5063 - val_loss: 0.5502 - val_mse: 0.5502\n",
      "Epoch 129/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.5042 - mse: 0.5042 - val_loss: 0.5420 - val_mse: 0.5420\n",
      "Epoch 130/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.5005 - mse: 0.5005 - val_loss: 0.5539 - val_mse: 0.5539\n",
      "Epoch 131/200\n",
      "1119/1119 [==============================] - 0s 90us/sample - loss: 0.4997 - mse: 0.4997 - val_loss: 0.5375 - val_mse: 0.5375\n",
      "Epoch 132/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4941 - mse: 0.4941 - val_loss: 0.5410 - val_mse: 0.5410\n",
      "Epoch 133/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4923 - mse: 0.4923 - val_loss: 0.5358 - val_mse: 0.5358\n",
      "Epoch 134/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.4950 - mse: 0.4950 - val_loss: 0.5316 - val_mse: 0.5316\n",
      "Epoch 135/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4892 - mse: 0.4892 - val_loss: 0.5404 - val_mse: 0.5404\n",
      "Epoch 136/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.4857 - mse: 0.4857 - val_loss: 0.5288 - val_mse: 0.5288\n",
      "Epoch 137/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.4849 - mse: 0.4849 - val_loss: 0.5296 - val_mse: 0.5296\n",
      "Epoch 138/200\n",
      "1119/1119 [==============================] - 0s 93us/sample - loss: 0.4897 - mse: 0.4897 - val_loss: 0.5461 - val_mse: 0.5461\n",
      "Epoch 139/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4830 - mse: 0.4830 - val_loss: 0.5270 - val_mse: 0.5270\n",
      "Epoch 140/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.4787 - mse: 0.4787 - val_loss: 0.5228 - val_mse: 0.5228\n",
      "Epoch 141/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4782 - mse: 0.4782 - val_loss: 0.5123 - val_mse: 0.5123\n",
      "Epoch 142/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.4719 - mse: 0.4719 - val_loss: 0.5273 - val_mse: 0.5273\n",
      "Epoch 143/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.4699 - mse: 0.4699 - val_loss: 0.5204 - val_mse: 0.5204\n",
      "Epoch 144/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.4692 - mse: 0.4692 - val_loss: 0.5119 - val_mse: 0.5119\n",
      "Epoch 145/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4674 - mse: 0.4674 - val_loss: 0.5327 - val_mse: 0.5327\n",
      "Epoch 146/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4725 - mse: 0.4725 - val_loss: 0.5160 - val_mse: 0.5160\n",
      "Epoch 147/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.4683 - mse: 0.4683 - val_loss: 0.5211 - val_mse: 0.5211\n",
      "Epoch 148/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4657 - mse: 0.4657 - val_loss: 0.5375 - val_mse: 0.5375\n",
      "Epoch 149/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4674 - mse: 0.4674 - val_loss: 0.5181 - val_mse: 0.5181\n",
      "Epoch 150/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4622 - mse: 0.4622 - val_loss: 0.4992 - val_mse: 0.4992\n",
      "Epoch 151/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4593 - mse: 0.4593 - val_loss: 0.5050 - val_mse: 0.5050\n",
      "Epoch 152/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4612 - mse: 0.4612 - val_loss: 0.5230 - val_mse: 0.5230\n",
      "Epoch 153/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4749 - mse: 0.4749 - val_loss: 0.5084 - val_mse: 0.5084\n",
      "Epoch 154/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4609 - mse: 0.4609 - val_loss: 0.4968 - val_mse: 0.4968\n",
      "Epoch 155/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.4575 - mse: 0.4575 - val_loss: 0.4956 - val_mse: 0.4956\n",
      "Epoch 156/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4524 - mse: 0.4524 - val_loss: 0.5224 - val_mse: 0.5224\n",
      "Epoch 157/200\n",
      "1119/1119 [==============================] - 0s 85us/sample - loss: 0.4559 - mse: 0.4559 - val_loss: 0.4960 - val_mse: 0.4960\n",
      "Epoch 158/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4484 - mse: 0.4484 - val_loss: 0.4900 - val_mse: 0.4900\n",
      "Epoch 159/200\n",
      "1119/1119 [==============================] - 0s 91us/sample - loss: 0.4526 - mse: 0.4526 - val_loss: 0.4905 - val_mse: 0.4905\n",
      "Epoch 160/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.4480 - mse: 0.4480 - val_loss: 0.4870 - val_mse: 0.4870\n",
      "Epoch 161/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.5069 - val_mse: 0.5069\n",
      "Epoch 162/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4547 - mse: 0.4547 - val_loss: 0.4797 - val_mse: 0.4797\n",
      "Epoch 163/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4484 - mse: 0.4484 - val_loss: 0.4818 - val_mse: 0.4818\n",
      "Epoch 164/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4437 - mse: 0.4437 - val_loss: 0.4843 - val_mse: 0.4843\n",
      "Epoch 165/200\n",
      "1119/1119 [==============================] - 0s 87us/sample - loss: 0.4512 - mse: 0.4512 - val_loss: 0.4750 - val_mse: 0.4750\n",
      "Epoch 166/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4413 - mse: 0.4413 - val_loss: 0.4845 - val_mse: 0.4845\n",
      "Epoch 167/200\n",
      "1119/1119 [==============================] - 0s 92us/sample - loss: 0.4433 - mse: 0.4433 - val_loss: 0.4836 - val_mse: 0.4836\n",
      "Epoch 168/200\n",
      "1119/1119 [==============================] - 0s 86us/sample - loss: 0.4400 - mse: 0.4400 - val_loss: 0.4793 - val_mse: 0.4793\n",
      "Epoch 169/200\n",
      "1119/1119 [==============================] - 0s 88us/sample - loss: 0.4392 - mse: 0.4392 - val_loss: 0.4963 - val_mse: 0.4963\n",
      "Epoch 170/200\n",
      "1119/1119 [==============================] - 0s 89us/sample - loss: 0.4388 - mse: 0.4388 - val_loss: 0.4835 - val_mse: 0.4835\n",
      "Epoch 171/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4372 - mse: 0.4372 - val_loss: 0.4704 - val_mse: 0.4704\n",
      "Epoch 172/200\n",
      "1119/1119 [==============================] - 0s 82us/sample - loss: 0.4464 - mse: 0.4464 - val_loss: 0.4809 - val_mse: 0.4809\n",
      "Epoch 173/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4421 - mse: 0.4421 - val_loss: 0.4791 - val_mse: 0.4791\n",
      "Epoch 174/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4478 - mse: 0.4478 - val_loss: 0.4741 - val_mse: 0.4741\n",
      "Epoch 175/200\n",
      "1119/1119 [==============================] - 0s 83us/sample - loss: 0.4388 - mse: 0.4388 - val_loss: 0.4893 - val_mse: 0.4893\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4351 - mse: 0.4351 - val_loss: 0.4837 - val_mse: 0.4837\n",
      "Epoch 177/200\n",
      "1119/1119 [==============================] - 0s 84us/sample - loss: 0.4328 - mse: 0.4328 - val_loss: 0.4722 - val_mse: 0.4722\n",
      "Epoch 178/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4345 - mse: 0.4345 - val_loss: 0.4729 - val_mse: 0.4729\n",
      "Epoch 179/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4329 - mse: 0.4329 - val_loss: 0.4855 - val_mse: 0.4855\n",
      "Epoch 180/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4351 - mse: 0.4351 - val_loss: 0.4961 - val_mse: 0.4961\n",
      "Epoch 181/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4372 - mse: 0.4372 - val_loss: 0.4815 - val_mse: 0.4815\n",
      "Epoch 182/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4383 - mse: 0.4383 - val_loss: 0.4676 - val_mse: 0.4676\n",
      "Epoch 183/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4368 - mse: 0.4368 - val_loss: 0.4627 - val_mse: 0.4627\n",
      "Epoch 184/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4322 - mse: 0.4322 - val_loss: 0.4946 - val_mse: 0.4946\n",
      "Epoch 185/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4284 - mse: 0.4284 - val_loss: 0.4695 - val_mse: 0.4695\n",
      "Epoch 186/200\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.4355 - mse: 0.4355 - val_loss: 0.4809 - val_mse: 0.4809\n",
      "Epoch 187/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4517 - mse: 0.4517 - val_loss: 0.4990 - val_mse: 0.4990\n",
      "Epoch 188/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4473 - mse: 0.4473 - val_loss: 0.4886 - val_mse: 0.4886\n",
      "Epoch 189/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4274 - mse: 0.4274 - val_loss: 0.4714 - val_mse: 0.4714\n",
      "Epoch 190/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4311 - mse: 0.4311 - val_loss: 0.4752 - val_mse: 0.4752\n",
      "Epoch 191/200\n",
      "1119/1119 [==============================] - 0s 79us/sample - loss: 0.4331 - mse: 0.4331 - val_loss: 0.4781 - val_mse: 0.4781\n",
      "Epoch 192/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4252 - mse: 0.4252 - val_loss: 0.4742 - val_mse: 0.4742\n",
      "Epoch 193/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4287 - mse: 0.4287 - val_loss: 0.4626 - val_mse: 0.4626\n",
      "Epoch 194/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4253 - mse: 0.4253 - val_loss: 0.4833 - val_mse: 0.4833\n",
      "Epoch 195/200\n",
      "1119/1119 [==============================] - 0s 77us/sample - loss: 0.4353 - mse: 0.4353 - val_loss: 0.4660 - val_mse: 0.4660\n",
      "Epoch 196/200\n",
      "1119/1119 [==============================] - 0s 80us/sample - loss: 0.4315 - mse: 0.4315 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 197/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4362 - mse: 0.4362 - val_loss: 0.4905 - val_mse: 0.4905\n",
      "Epoch 198/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4293 - mse: 0.4293 - val_loss: 0.4723 - val_mse: 0.4723\n",
      "Epoch 199/200\n",
      "1119/1119 [==============================] - 0s 78us/sample - loss: 0.4431 - mse: 0.4431 - val_loss: 0.4685 - val_mse: 0.4685\n",
      "Epoch 200/200\n",
      "1119/1119 [==============================] - 0s 81us/sample - loss: 0.4302 - mse: 0.4302 - val_loss: 0.4560 - val_mse: 0.4560\n"
     ]
    }
   ],
   "source": [
    "nn.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "model_1 = nn.fit(X, y, validation_split=0.3, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a47664e90>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " plt.plot(model.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = nn.fit(X, y, validation_split=0.3, epochs=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
